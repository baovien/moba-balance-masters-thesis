{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo: \n",
    "\n",
    "* Classifier per hero * role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pickle \n",
    "import tqdm\n",
    "import tarfile\n",
    "from scipy import sparse\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tarfile.open(\"../data/parsed/opendota_parsed_matches.tar.gz\", 'r:gz') as zfp:\n",
    "#     for filename in zfp.getnames():\n",
    "#         match = pickle.load(zfp.extractfile(filename))\n",
    "#         print(match)\n",
    "#         break\n",
    "\n",
    "zfp = tarfile.open(\"../data/opendota_parsed_matches.tar.gz\", 'r:gz')\n",
    "all_filenames = zfp.getnames()\n",
    "filenames = all_filenames[1:]\n",
    "\n",
    "# fp = zfp.extractfile(filenames[0])\n",
    "# fp.seek(0)\n",
    "# match = pickle.loads(fp.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"../data/dataset_positions.pkl\" \n",
    "\n",
    "assert not os.path.exists(output_path)\n",
    "\n",
    "def get_rank(rank: int):\n",
    "    oh = np.zeros(5)\n",
    "    oh[rank] = 1\n",
    "    return oh\n",
    "\n",
    "def kda(kills, deaths, assists):\n",
    "    return kills + assists / (deaths + 1)\n",
    "\n",
    "def extract_data_point(match):\n",
    "    players = match[\"players\"]\n",
    "    t0 = list(filter(lambda p: p[\"isRadiant\"], players))\n",
    "    t1 = list(filter(lambda p: not p[\"isRadiant\"], players))\n",
    "    xs = {}\n",
    "    ys = {}\n",
    "    unassigned_roles_counter = Counter()\n",
    "\n",
    "    for team in [t0, t1]:\n",
    "        hids = [p[\"hero_id\"] for p in team]\n",
    "\n",
    "        # !Ranks\n",
    "        attributes = [\"gold_per_min\", \"xp_per_min\", \"kills\", \"deaths\", \"assists\", \"last_hits\", \"hero_damage\", \"tower_damage\"]\n",
    "        ranks = {}\n",
    "        \n",
    "        for attr in attributes:\n",
    "            ranks[attr] = sorted([(p[\"hero_id\"], p[attr]) for p in team], key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        wards_placed = {}\n",
    "        for p in team:\n",
    "            item_uses = p[\"item_uses\"]\n",
    "            c = 0\n",
    "            if \"ward_observer\" in item_uses:\n",
    "                c += item_uses[\"ward_observer\"]\n",
    "            if \"ward_dispenser\" in item_uses:\n",
    "                c += item_uses[\"ward_dispenser\"]\n",
    "            if \"ward_sentry\" in item_uses:\n",
    "                c += item_uses[\"ward_sentry\"]\n",
    "                \n",
    "            wards_placed[p[\"hero_id\"]] = c\n",
    "\n",
    "        # !Find roles\n",
    "\n",
    "        support_candidates_4 = []\n",
    "        support_candidates_5 = []\n",
    "        unassigned_candidates = []\n",
    "        final_roles = {}\n",
    "        lanes = defaultdict(list)\n",
    "        players = defaultdict(dict)\n",
    "        for p in team:\n",
    "            lanes[p[\"lane\"]].append({\"hid\": p[\"hero_id\"], \"gpm\": p[\"gold_per_min\"], \"wards\": wards_placed[p[\"hero_id\"]]})\n",
    "            players[p[\"hero_id\"]] = {\"gpm\": p[\"gold_per_min\"], \"last_hits\": p[\"last_hits\"], \"wards\": wards_placed[p[\"hero_id\"]]}\n",
    "        \n",
    "\n",
    "        for lane in lanes.items():\n",
    "            if len(lane[1]) == 5:\n",
    "                return \"invalid_match\", None, None\n",
    "\n",
    "        if len(lanes[1]) > 1:\n",
    "            highest_gpm_hero = max(lanes[1], key=lambda x: x[\"gpm\"])\n",
    "            everyone_except_highest_gpm_hero_id = [x[\"hid\"] for x in lanes[1] if x[\"hid\"] != highest_gpm_hero[\"hid\"]]\n",
    "            support_candidates_5.extend(everyone_except_highest_gpm_hero_id)\n",
    "            final_roles[1] = highest_gpm_hero[\"hid\"]\n",
    "        elif len(lanes[1]) == 1:\n",
    "            final_roles[1] = lanes[1][0][\"hid\"]\n",
    "            \n",
    "        if len(lanes[2]) > 1:\n",
    "            highest_gpm_hero = max(lanes[2], key=lambda x: x[\"gpm\"])\n",
    "            everyone_except_highest_gpm_hero_id = [x[\"hid\"] for x in lanes[2] if x[\"hid\"] != highest_gpm_hero[\"hid\"]]\n",
    "            support_candidates_4.extend(everyone_except_highest_gpm_hero_id)\n",
    "            final_roles[2] = highest_gpm_hero[\"hid\"]\n",
    "        elif len(lanes[2]) == 1:\n",
    "            final_roles[2] = lanes[2][0][\"hid\"]\n",
    "\n",
    "        if len(lanes[3]) > 1:\n",
    "            highest_gpm_hero = max(lanes[3], key=lambda x: x[\"gpm\"])\n",
    "            everyone_except_highest_gpm_hero_id = [x[\"hid\"] for x in lanes[3] if x[\"hid\"] != highest_gpm_hero[\"hid\"]]\n",
    "            support_candidates_4.extend(everyone_except_highest_gpm_hero_id)\n",
    "            final_roles[3] = highest_gpm_hero[\"hid\"]\n",
    "        elif len(lanes[3]) == 1:\n",
    "            final_roles[3] = lanes[3][0][\"hid\"]\n",
    "\n",
    "        all_hero_ids = [x[\"hid\"] for x in lanes[4]]\n",
    "        support_candidates_4.extend(all_hero_ids)\n",
    "        \n",
    "        all_hero_ids = [x[\"hid\"] for x in lanes[5]]\n",
    "        support_candidates_5.extend(all_hero_ids)\n",
    "\n",
    "        # ! Assign pos 4 and 5\n",
    "        support_candidates_4 = list(set(support_candidates_4))\n",
    "        support_candidates_5 = list(set(support_candidates_5))\n",
    "\n",
    "        if len(support_candidates_5) > 1:\n",
    "            support_candidates_5_wards_max = max(support_candidates_5, key=lambda x: wards_placed[x])\n",
    "            final_roles[5] = support_candidates_5_wards_max\n",
    "            unassigned_candidates.extend([x for x in support_candidates_5 if x != support_candidates_5_wards_max])\n",
    "        elif len(support_candidates_5) == 1: \n",
    "            final_roles[5] = support_candidates_5[0]\n",
    "\n",
    "        if len(support_candidates_4) > 1:\n",
    "            support_candidates_4_wards_max = max(support_candidates_4, key=lambda x: wards_placed[x])\n",
    "            final_roles[4] = support_candidates_4_wards_max\n",
    "            unassigned_candidates.extend([x for x in support_candidates_4 if x != support_candidates_4_wards_max])\n",
    "        elif len(support_candidates_4) == 1:\n",
    "            final_roles[4] = support_candidates_4[0]\n",
    "\n",
    "        # ! check if all roles are assigned\n",
    "        unassigned_candidates = list(set(unassigned_candidates))\n",
    "        for role in lanes:\n",
    "            if role not in final_roles:\n",
    "                if len(unassigned_candidates) == 1:\n",
    "                    final_roles[role] = unassigned_candidates[0]\n",
    "                    unassigned_candidates.pop()\n",
    "                    # print(\"Assigned {} to role {}\".format(final_roles[role], role))\n",
    "                elif len(unassigned_candidates) > 1:\n",
    "                    unassigned_candidates_gpm_wards = [(x, players[x][\"gpm\"], players[x][\"wards\"]) for x in unassigned_candidates]\n",
    "                    final_roles_gpm_wards = [(x, players[x][\"gpm\"], players[x][\"wards\"]) for x in final_roles.values()]\n",
    "                    if role == 1: \n",
    "                        max_gpm_hero = max(unassigned_candidates, key=lambda x: players[x][\"gpm\"])\n",
    "                        final_roles[role] = max_gpm_hero\n",
    "                        unassigned_roles_counter[role] += 1\n",
    "                        unassigned_candidates.pop(unassigned_candidates.index(max_gpm_hero))\n",
    "                        # print(\"Role {} not assigned. Assigning {}, which has {}. {}\".format(role, max_gpm_hero, players[max_gpm_hero], unassigned_candidates_gpm_wards))\n",
    "                        # print(final_roles_gpm_wards)\n",
    "\n",
    "                    elif role == 5: \n",
    "                        max_wards_hero = max(unassigned_candidates, key=lambda x: wards_placed[x])\n",
    "                        final_roles[role] = max_wards_hero\n",
    "                        unassigned_roles_counter[role] += 1\n",
    "                        unassigned_candidates.pop(unassigned_candidates.index(max_wards_hero))\n",
    "                        # print(\"Role {} not assigned. Assigning {}, which has {}. {}\".format(role, max_wards_hero, players[max_wards_hero], unassigned_candidates_gpm_wards))\n",
    "                        # print(final_roles_gpm_wards)\n",
    "\n",
    "                    elif role == 3:\n",
    "                        max_gpm_hero = max(unassigned_candidates, key=lambda x: players[x][\"gpm\"])\n",
    "                        final_roles[role] = max_gpm_hero\n",
    "                        unassigned_roles_counter[role] += 1\n",
    "                        unassigned_candidates.pop(unassigned_candidates.index(max_gpm_hero))\n",
    "                        # print(\"Role {} not assigned. Assigning {}, which has {}. {}\".format(role, max_gpm_hero, players[max_gpm_hero], unassigned_candidates_gpm_wards))\n",
    "                        # print(final_roles_gpm_wards)\n",
    "                else:\n",
    "                    raise Exception(\"No more heroes to assign\")\n",
    "       \n",
    "\n",
    "        # ! Assign pos 1, 2, 3\n",
    "        for role in lanes:\n",
    "            if role not in final_roles:\n",
    "                if len(unassigned_candidates) == 1:\n",
    "                    final_roles[role] = unassigned_candidates[0]\n",
    "                    unassigned_candidates.pop()\n",
    "                    unassigned_roles_counter[role] += 1\n",
    "\n",
    "                    # print(\"Assigned {} to role {}\".format(final_roles[role], role))\n",
    "        \n",
    "        #! fixing \n",
    "        hero_id_last_hits_tuple_list_unassigned_roles = [(x, players[x][\"last_hits\"]) for x in unassigned_candidates]\n",
    "        hero_id_last_hits_tuple_list_unassigned_roles.sort(key=lambda x: x[1], reverse=True)\n",
    "        for role_id in range(1,6):\n",
    "            if role_id not in final_roles:\n",
    "                final_roles[role_id] = hero_id_last_hits_tuple_list_unassigned_roles[0][0]\n",
    "                unassigned_roles_counter[role_id] += 1\n",
    "                hero_id_last_hits_tuple_list_unassigned_roles.pop(0)\n",
    "\n",
    "\n",
    "        if len(final_roles) != 5:\n",
    "            print(\"final roles: \", final_roles)\n",
    "            print(\"support candidates 4: \", support_candidates_4)\n",
    "            print(\"support candidates 5: \", support_candidates_5)\n",
    "            print(\"wards placed: \", wards_placed)\n",
    "            raise Exception(\"Not all roles assigned\")\n",
    "\n",
    "\n",
    "        # !Add features\n",
    "        for p in team:\n",
    "            features = []\n",
    "            hid = p[\"hero_id\"]\n",
    "\n",
    "            teammates = np.zeros((136))\n",
    "            for team_hid in hids:\n",
    "                if team_hid != hid:\n",
    "                    teammates[team_hid] = 1.\n",
    "            \n",
    "            features.append(teammates)\n",
    "            \n",
    "            for rank in ranks: \n",
    "                features.append(get_rank(ranks[rank].index((hid, p[rank]))))\n",
    "\n",
    "\n",
    "            #! Add labels\n",
    "            \n",
    "            flipped_final_roles = {v: k for k, v in final_roles.items()}\n",
    "            position = flipped_final_roles[hid]                \n",
    "            \n",
    "            xs[hid] = np.concatenate(features)\n",
    "            ys[hid] = position\n",
    "    \n",
    "    return xs, ys, unassigned_roles_counter\n",
    "\n",
    "\n",
    "\n",
    "# !Main loop\n",
    "trainingset = defaultdict(list)\n",
    "labels = defaultdict(list)\n",
    "skips = 0\n",
    "un_counter = Counter()\n",
    "for fname in tqdm.tqdm(filenames):\n",
    "    leaver = False\n",
    "    fp = zfp.extractfile(fname)\n",
    "    fp.seek(0)\n",
    "    match = pickle.loads(fp.read())\n",
    "    xs, ys, ur = extract_data_point(match)\n",
    "    if xs == \"invalid_match\":\n",
    "        skips += 1\n",
    "        continue\n",
    "    un_counter += ur\n",
    "    \n",
    "    for hid, x in xs.items():\n",
    "        trainingset[hid].append(x)\n",
    "        labels[hid].append(ys[hid])\n",
    "\n",
    "with open(output_path, 'wb') as fp: \n",
    "    pickle.dump({\"xs\": trainingset, \"ys\": labels}, fp)\n",
    "\n",
    "print(\"=\" * 20)\n",
    "print(un_counter.most_common())\n",
    "print(\"skips\", skips)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"../data/dataset_positions.pkl\" \n",
    "\n",
    "with open(output_path, 'rb') as fp:\n",
    "    data = pickle.load(fp)\n",
    "\n",
    "xs = data[\"xs\"]\n",
    "ys = data[\"ys\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../../data/heroes.json\", \"r\") as fp:\n",
    "  heroes = json.load(fp)\n",
    "\n",
    "safelane = [\"Anti-Mage\", \"Arc Warden\", \"Bloodseeker\", \"Chaos Knight\", \"Clinkz\", \"Drow Ranger\", \"Faceless Void\", \n",
    "\"Gyrocopter\", \"Juggernaut\", \"Lifestealer\", \"Luna\", \"Medusa\", \"Monkey King\", \"Morphling\", \"Naga Siren\", \"Phantom Assassin\", \n",
    "\"Phantom Lancer\", \"Riki\", \"Slark\", \"Spectre\", \"Sven\", \"Terrorblade\", \"Tiny\", \"Troll Warlord\", \"Ursa\", \"Weaver\", \"Wraith King\"]\n",
    "safelane_name_to_id = [x[\"id\"] for x in heroes if x[\"localized_name\"] in safelane]\n",
    "print(len(safelane), len(safelane_name_to_id))\n",
    "\n",
    "midlane = [\"Alchemist\", \"Arc Warden\", \"Batrider\", \"Broodmother\", \"Death Prophet\", \"Ember Spirit\", \n",
    "\"Huskar\", \"Invoker\", \"Kunkka\", \"Leshrac\", \"Lina\", \"Lone Druid\", \"Meepo\", \"Necrophos\", \"Outworld Destroyer\", \n",
    "\"Puck\", \"Pugna\", \"Queen of Pain\", \"Razor\", \"Shadow Fiend\", \"Sniper\", \"Storm Spirit\", \n",
    "\"Templar Assassin\", \"Tinker\", \"Viper\", \"Visage\", \"Void Spirit\", \"Zeus\"]\n",
    "midlane_name_to_id = [x[\"id\"] for x in heroes if x[\"localized_name\"] in midlane]\n",
    "print(len(midlane), len(midlane_name_to_id))\n",
    "\n",
    "offlane = [\"Axe\", \"Beastmaster\", \"Bloodseeker\", \"Brewmaster\", \"Bristleback\", \n",
    "\"Centaur Warrunner\", \"Chaos Knight\", \"Dark Seer\", \"Dawnbreaker\", \"Death Prophet\", \"Doom\", \n",
    "\"Dragon Knight\", \"Earthshaker\", \"Elder Titan\", \"Enigma\", \"Legion Commander\", \"Lycan\", \n",
    "\"Mars\", \"Nature's Prophet\", \"Necrophos\", \"Night Stalker\", \"Pangolier\", \n",
    "\"Razor\", \"Sand King\", \"Slardar\", \"Spirit Breaker\", \"Tidehunter\", \"Timbersaw\", \"Underlord\", \"Venomancer\", \"Viper\"]\n",
    "\n",
    "offlane_name_to_id = [x[\"id\"] for x in heroes if x[\"localized_name\"] in offlane]\n",
    "print(len(offlane),len(offlane_name_to_id))\n",
    "\n",
    "soft_support = [\"Bounty Hunter\", \"Chen\", \"Clockwerk\", \"Dark Willow\", \"Earth Spirit\", \"Earthshaker\", \"Enigma\", \n",
    "\"Grimstroke\", \"Hoodwink\", \"Keeper of the Light\", \"Mirana\", \"Nyx Assassin\", \"Phoenix\", \"Pudge\", \"Rubick\", \n",
    "\"Shadow Demon\", \"Shadow Shaman\", \"Silencer\", \"Skywrath Mage\", \"Snapfire\", \"Spirit Breaker\", \"Techies\", \n",
    "\"Treant Protector\", \"Tusk\", \"Venomancer\", \"Weaver\", \"Windranger\"]\n",
    "\n",
    "soft_support_name_to_id = [x[\"id\"] for x in heroes if x[\"localized_name\"] in soft_support]\n",
    "print(len(soft_support), len(soft_support_name_to_id))\n",
    "\n",
    "hard_support = [\"Abaddon\", \"Ancient Apparition\", \"Bane\", \"Chen\", \"Crystal Maiden\", \"Dark Willow\", \"Dazzle\", \"Disruptor\", \n",
    "\"Enchantress\", \"Grimstroke\", \"Io\", \"Jakiro\", \"Keeper of the Light\", \"Lich\", \"Lion\", \"Ogre Magi\", \"Omniknight\", \"Oracle\", \"Shadow Demon\", \n",
    "\"Shadow Shaman\", \"Silencer\", \"Snapfire\", \"Treant Protector\", \"Vengeful Spirit\", \"Undying\", \"Warlock\", \"Winter Wyvern\", \"Witch Doctor\"]\n",
    "hard_support_name_to_id = [x[\"id\"] for x in heroes if x[\"localized_name\"] in hard_support]\n",
    "print(len(hard_support), len(hard_support_name_to_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_dict = defaultdict(lambda: np.zeros(5))\n",
    "\n",
    "for h in heroes:\n",
    "    weights_dict[h[\"id\"]] = np.array([.1, .1, .1, .1, .1])\n",
    "\n",
    "lane_assist = [safelane_name_to_id, midlane_name_to_id, offlane_name_to_id, soft_support_name_to_id, hard_support_name_to_id]\n",
    "\n",
    "for k, lane in enumerate(lane_assist):\n",
    "    for hid in lane:\n",
    "        weights_dict[hid][k] = 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "clfs = []\n",
    "scores = [] \n",
    "\n",
    "for hid in tqdm.tqdm(xs):\n",
    "    x = np.vstack(xs[hid])\n",
    "    y = np.hstack(ys[hid]) - 1\n",
    " \n",
    "    class_weight = weights_dict[hid]\n",
    "    class_weight_dict = {{e, v} for e, v in enumerate(class_weight)}\n",
    "    print(class_weight_dict)\n",
    "    break\n",
    "    clf = LogisticRegression(multi_class=\"ovr\", max_iter=200, n_jobs=-1, solver=\"lbfgs\", class_weight=class_weight)\n",
    "    # clf = RandomForestClassifier()\n",
    "    clf.fit(x, y)\n",
    "\n",
    "    # print(hid, \"score is: \", clf.score(x,y))\n",
    "    clfs.append(clf)\n",
    "    scores.append(clf.score(x,y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(scores).mean())\n",
    "\n",
    "clfs[31].coef_[4, 136:136+5]\n",
    "\n",
    "# clfs[31].feature_importances_[136:136+5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(scores).mean())\n",
    "\n",
    "clfs[31].coef_[4, 136:136+5]\n",
    "\n",
    "# clfs[31].feature_importances_[136:136+5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y, return_counts=True)\n",
    "print(unique, counts)\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(y)\n",
    "df.plot.hist(xticks=[1, 2, 3, 4, 5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score,cross_val_predict, train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "print(np.mean(y_pred == y_test))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "clf = LogisticRegression(random_state=0)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "print(np.mean(y_pred == y_test))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score,cross_val_predict, train_test_split\n",
    "\n",
    "\n",
    "# for hero, train a logistic regression model and add to VotingClassifier\n",
    "estimators = []\n",
    "\n",
    "\n",
    "clf = LogisticRegression(multi_class='multinomial', random_state=1)\n",
    "\n",
    "eclf1 = VotingClassifier(estimators=estimators, voting='hard')\n",
    "eclf1 = eclf1.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eclf1.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(eclf1.named_estimators_.lr.predict(x), eclf1.named_estimators_['lr'].predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9795b5b0f359c9a3e41b413a20d82be0b706bb1e3ab3cb76e6b985ca6d9563dc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('dota': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
