{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pickle \n",
    "import tqdm\n",
    "import tarfile\n",
    "from scipy import sparse\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "def load_data(path):\n",
    "    with open(path, 'rb') as fp:\n",
    "        data = pickle.load(fp)\n",
    "\n",
    "    return data[\"xs\"], data[\"ys\"]\n",
    "\n",
    "def load_weights_dict(path):\n",
    "    with open(path, 'rb') as fp:\n",
    "        weights_dict = pickle.load(fp)\n",
    "    return weights_dict\n",
    "\n",
    "def get_dummy_classifier():\n",
    "    return DummyClassifier(strategy=\"constant\", constant=0)\n",
    "\n",
    "output_path = \"../data/dataset_positions_winners.pkl\" \n",
    "weights_path = \"../data/weights_dict.pkl\"\n",
    "xs, ys = load_data(output_path)\n",
    "weights_dict = load_weights_dict(weights_path)\n",
    "\n",
    "clfs = {}\n",
    "scores = {}\n",
    "scores_dict = {}\n",
    "n_features = np.vstack(xs[1]).shape[1]\n",
    "for hid in tqdm.tqdm(xs):\n",
    "    try:\n",
    "        x = np.vstack(xs[hid])\n",
    "        y = np.hstack(ys[hid])\n",
    "        \n",
    "        class_weight = {e:v for e, v in enumerate(weights_dict[hid])}\n",
    "        unique = np.unique(np.hstack(ys[hid]))\n",
    "\n",
    "        for class_role in [1, 2, 3, 4, 5]:\n",
    "            if not class_role in unique.tolist():\n",
    "                print('added classrole', class_role, \"for hero\", hid)\n",
    "                xs[hid].append(np.zeros((n_features)))\n",
    "                ys[hid].append(class_role)\n",
    "\n",
    "        x = np.vstack(xs[hid])\n",
    "        y = np.hstack(ys[hid]) - 1\n",
    "\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        clf = DecisionTreeClassifier(class_weight=class_weight)\n",
    "        clf.fit(x_train, y_train)\n",
    "\n",
    "        score = clf.score(x_test, y_test)\n",
    "        clfs[hid] = clf\n",
    "        scores[hid] = score\n",
    "        scores_dict[hid] = score\n",
    "\n",
    "\n",
    "    except:\n",
    "        print(\"creashed on hid: \", hid)\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum_teammates = clfs[hid].feature_importances_[:136].sum()\n",
    "# sum_features = clfs[hid].feature_importances_[136:].sum()\n",
    "\n",
    "\n",
    "feature_sum = dict((k, 0.0) for k in [\"gold_per_min\", \"xp_per_min\", \"kills\", \"deaths\", \"assists\", \"last_hits\", \"hero_damage\", \"tower_damage\"])\n",
    "\n",
    "for hid in xs:\n",
    "    for k, l in enumerate([\"gold_per_min\", \"xp_per_min\", \"kills\", \"deaths\", \"assists\", \"last_hits\", \"hero_damage\", \"tower_damage\"]):\n",
    "        index = 136 + k * 5\n",
    "        s = clfs[hid].feature_importances_[index:index+5].sum()\n",
    "        feature_sum[l] += s\n",
    "\n",
    "\n",
    "\n",
    "pprint(feature_sum.items())\n",
    "# sum_teammates, sum_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "hid = 129\n",
    "print(confusion_matrix(clfs[hid].predict(np.vstack(xs[hid])), np.hstack(ys[hid])-1))\n",
    "\n",
    "counts, unique = np.unique(np.hstack(ys[hid])-1, return_counts=True)\n",
    "print(counts, unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(clfs[hid].predict(np.vstack(xs[hid])), np.hstack(ys[hid])-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(scores_dict.items())\n",
    "a.sort(key=lambda x: x[1], reverse=False)\n",
    "\n",
    "hid_to_name = {x[\"id\"]:x[\"localized_name\"] for x in heroes}\n",
    "s_sum = []\n",
    "for k, v in a:\n",
    "    s_sum.append(v)\n",
    "    print(hid_to_name[k], k, v)\n",
    "\n",
    "np.mean(s_sum), np.median(s_sum)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
