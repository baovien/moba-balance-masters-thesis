{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pickle \n",
    "import tqdm\n",
    "import tarfile\n",
    "from scipy import sparse\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"../data/dataset_positions_winners.pkl\" \n",
    "\n",
    "with open(output_path, 'rb') as fp:\n",
    "    data = pickle.load(fp)\n",
    "\n",
    "xs = data[\"xs\"]\n",
    "ys = data[\"ys\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 27\n",
      "28 28\n",
      "31 31\n",
      "27 27\n",
      "28 28\n"
     ]
    }
   ],
   "source": [
    "with open(\"../../data/heroes.json\", \"r\") as fp:\n",
    "  heroes = json.load(fp)\n",
    "\n",
    "safelane = [\"Anti-Mage\", \"Arc Warden\", \"Bloodseeker\", \"Chaos Knight\", \"Clinkz\", \"Drow Ranger\", \"Faceless Void\", \n",
    "\"Gyrocopter\", \"Juggernaut\", \"Lifestealer\", \"Luna\", \"Medusa\", \"Monkey King\", \"Morphling\", \"Naga Siren\", \"Phantom Assassin\", \n",
    "\"Phantom Lancer\", \"Riki\", \"Slark\", \"Spectre\", \"Sven\", \"Terrorblade\", \"Tiny\", \"Troll Warlord\", \"Ursa\", \"Weaver\", \"Wraith King\"]\n",
    "safelane_name_to_id = [x[\"id\"] for x in heroes if x[\"localized_name\"] in safelane]\n",
    "print(len(safelane), len(safelane_name_to_id))\n",
    "\n",
    "midlane = [\"Alchemist\", \"Arc Warden\", \"Batrider\", \"Broodmother\", \"Death Prophet\", \"Ember Spirit\", \n",
    "\"Huskar\", \"Invoker\", \"Kunkka\", \"Leshrac\", \"Lina\", \"Lone Druid\", \"Meepo\", \"Necrophos\", \"Outworld Destroyer\", \n",
    "\"Puck\", \"Pugna\", \"Queen of Pain\", \"Razor\", \"Shadow Fiend\", \"Sniper\", \"Storm Spirit\", \n",
    "\"Templar Assassin\", \"Tinker\", \"Viper\", \"Visage\", \"Void Spirit\", \"Zeus\"]\n",
    "midlane_name_to_id = [x[\"id\"] for x in heroes if x[\"localized_name\"] in midlane]\n",
    "print(len(midlane), len(midlane_name_to_id))\n",
    "\n",
    "offlane = [\"Axe\", \"Beastmaster\", \"Bloodseeker\", \"Brewmaster\", \"Bristleback\", \n",
    "\"Centaur Warrunner\", \"Chaos Knight\", \"Dark Seer\", \"Dawnbreaker\", \"Death Prophet\", \"Doom\", \n",
    "\"Dragon Knight\", \"Earthshaker\", \"Elder Titan\", \"Enigma\", \"Legion Commander\", \"Lycan\", \n",
    "\"Mars\", \"Nature's Prophet\", \"Necrophos\", \"Night Stalker\", \"Pangolier\", \n",
    "\"Razor\", \"Sand King\", \"Slardar\", \"Spirit Breaker\", \"Tidehunter\", \"Timbersaw\", \"Underlord\", \"Venomancer\", \"Viper\"]\n",
    "\n",
    "offlane_name_to_id = [x[\"id\"] for x in heroes if x[\"localized_name\"] in offlane]\n",
    "print(len(offlane),len(offlane_name_to_id))\n",
    "\n",
    "soft_support = [\"Bounty Hunter\", \"Chen\", \"Clockwerk\", \"Dark Willow\", \"Earth Spirit\", \"Earthshaker\", \"Enigma\", \n",
    "\"Grimstroke\", \"Hoodwink\", \"Keeper of the Light\", \"Mirana\", \"Nyx Assassin\", \"Phoenix\", \"Pudge\", \"Rubick\", \n",
    "\"Shadow Demon\", \"Shadow Shaman\", \"Silencer\", \"Skywrath Mage\", \"Snapfire\", \"Spirit Breaker\", \"Techies\", \n",
    "\"Treant Protector\", \"Tusk\", \"Venomancer\", \"Weaver\", \"Windranger\"]\n",
    "\n",
    "soft_support_name_to_id = [x[\"id\"] for x in heroes if x[\"localized_name\"] in soft_support]\n",
    "print(len(soft_support), len(soft_support_name_to_id))\n",
    "\n",
    "hard_support = [\"Abaddon\", \"Ancient Apparition\", \"Bane\", \"Chen\", \"Crystal Maiden\", \"Dark Willow\", \"Dazzle\", \"Disruptor\", \n",
    "\"Enchantress\", \"Grimstroke\", \"Io\", \"Jakiro\", \"Keeper of the Light\", \"Lich\", \"Lion\", \"Ogre Magi\", \"Omniknight\", \"Oracle\", \"Shadow Demon\", \n",
    "\"Shadow Shaman\", \"Silencer\", \"Snapfire\", \"Treant Protector\", \"Vengeful Spirit\", \"Undying\", \"Warlock\", \"Winter Wyvern\", \"Witch Doctor\"]\n",
    "hard_support_name_to_id = [x[\"id\"] for x in heroes if x[\"localized_name\"] in hard_support]\n",
    "print(len(hard_support), len(hard_support_name_to_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_dict = defaultdict(lambda: np.zeros(5))\n",
    "\n",
    "for h in heroes:\n",
    "    weights_dict[h[\"id\"]] = np.array([.1, .1, .1, .1, .1])\n",
    "\n",
    "lane_assist = [safelane_name_to_id, midlane_name_to_id, offlane_name_to_id, soft_support_name_to_id, hard_support_name_to_id]\n",
    "\n",
    "for k, lane in enumerate(lane_assist):\n",
    "    for hid in lane:\n",
    "        weights_dict[hid][k] = 1.\n",
    "\n",
    "{e:v for e, v in enumerate(weights_dict[4])}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:57<00:00,  2.09it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "\n",
    "def get_dummy_classifier():\n",
    "    return DummyClassifier(strategy=\"constant\", constant=0)\n",
    "\n",
    "clfs = {}\n",
    "scores = {}\n",
    "scores_dict = {}\n",
    "\n",
    "n_features = np.vstack(xs[1]).shape[1]\n",
    "for hid in tqdm.tqdm(xs):\n",
    "    try:\n",
    "        x = np.vstack(xs[hid])\n",
    "        y = np.hstack(ys[hid])\n",
    "        \n",
    "        class_weight = {e:v for e, v in enumerate(weights_dict[hid])}\n",
    "        unique = np.unique(np.hstack(ys[hid]))\n",
    "\n",
    "        for class_role in [1, 2, 3, 4, 5]:\n",
    "            if not class_role in unique.tolist():\n",
    "                print('added classrole', class_role, \"for hero\", hid)\n",
    "                xs[hid].append(np.zeros((n_features)))\n",
    "                ys[hid].append(class_role)\n",
    "\n",
    "        x = np.vstack(xs[hid])\n",
    "        y = np.hstack(ys[hid]) - 1\n",
    "\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        clf = LogisticRegression(multi_class=\"ovr\", max_iter=300, n_jobs=-1, solver=\"lbfgs\", class_weight=class_weight)\n",
    "        # clf = DecisionTreeClassifier(class_weight=class_weight)\n",
    "        clf.fit(x_train, y_train)\n",
    "\n",
    "        score = clf.score(x_test, y_test)\n",
    "        clfs[hid] = clf\n",
    "        scores[hid] = score\n",
    "        scores_dict[hid] = score\n",
    "\n",
    "\n",
    "    except:\n",
    "        print(\"creashed on hid: \", hid)\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4] [  30  118 1970  277   59]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "hid = 129\n",
    "confusion_matrix(clfs[hid].predict(np.vstack(xs[hid])), np.hstack(ys[hid])-1)\n",
    "\n",
    "counts, unique = np.unique(np.hstack(ys[hid])-1, return_counts=True)\n",
    "print(counts, unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[0 1 2 3 4] [1708  114 1632  365  417]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       1.00      0.83      0.91      2378\n",
      "           3       0.18      0.67      0.28        75\n",
      "           4       0.02      1.00      0.03         1\n",
      "\n",
      "    accuracy                           0.82      2454\n",
      "   macro avg       0.24      0.50      0.24      2454\n",
      "weighted avg       0.97      0.82      0.89      2454\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bao/anaconda3/envs/dota/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/bao/anaconda3/envs/dota/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/bao/anaconda3/envs/dota/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(clfs[hid].predict(np.vstack(xs[hid])), np.hstack(ys[hid])-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alchemist 73 0.43243243243243246\n",
      "Lone Druid 80 0.49056603773584906\n",
      "Keeper of the Light 90 0.5137614678899083\n",
      "Nature's Prophet 53 0.53125\n",
      "Omniknight 57 0.5333333333333333\n",
      "Vengeful Spirit 20 0.5529801324503312\n",
      "Techies 105 0.555956678700361\n",
      "Enchantress 58 0.5566037735849056\n",
      "Broodmother 61 0.56\n",
      "Bloodseeker 4 0.573170731707317\n",
      "Riki 32 0.5751295336787565\n",
      "Silencer 75 0.5798045602605864\n",
      "Undying 85 0.5844155844155844\n",
      "Rubick 86 0.5876460767946577\n",
      "Treant Protector 83 0.6060606060606061\n",
      "Bounty Hunter 62 0.6202090592334495\n",
      "Snapfire 128 0.6213592233009708\n",
      "Venomancer 40 0.624031007751938\n",
      "Chen 66 0.6296296296296297\n",
      "Nyx Assassin 88 0.6305732484076433\n",
      "Hoodwink 123 0.6318681318681318\n",
      "Pugna 45 0.6363636363636364\n",
      "Visage 92 0.6363636363636364\n",
      "Dark Willow 119 0.6385224274406333\n",
      "Skywrath Mage 101 0.638755980861244\n",
      "Razor 15 0.6412213740458015\n",
      "Clinkz 56 0.6413043478260869\n",
      "Viper 47 0.6416382252559727\n",
      "Shadow Demon 79 0.6481481481481481\n",
      "Dragon Knight 49 0.6483516483516484\n",
      "Pudge 14 0.6492462311557788\n",
      "Ogre Magi 84 0.6498740554156172\n",
      "Enigma 33 0.65\n",
      "Shadow Shaman 27 0.6591928251121076\n",
      "Elder Titan 103 0.6612903225806451\n",
      "Gyrocopter 72 0.6649214659685864\n",
      "Grimstroke 121 0.6655948553054662\n",
      "Monkey King 114 0.6661849710982659\n",
      "Huskar 59 0.6681614349775785\n",
      "Timbersaw 98 0.6687116564417178\n",
      "Phoenix 110 0.66875\n",
      "Winter Wyvern 112 0.6705539358600583\n",
      "Mirana 9 0.6745182012847966\n",
      "Lion 26 0.674712643678161\n",
      "Weaver 63 0.6788793103448276\n",
      "Io 91 0.6801346801346801\n",
      "Kunkka 23 0.6810126582278481\n",
      "Batrider 65 0.6823529411764706\n",
      "Sniper 35 0.6828046744574291\n",
      "Tiny 19 0.6847172081829122\n",
      "Jakiro 64 0.6848249027237354\n",
      "Leshrac 52 0.6850393700787402\n",
      "Abaddon 102 0.6857142857142857\n",
      "Death Prophet 43 0.6881720430107527\n",
      "Chaos Knight 81 0.7\n",
      "Morphling 10 0.7122641509433962\n",
      "Windranger 21 0.7165605095541401\n",
      "Ancient Apparition 68 0.7181008902077152\n",
      "Medusa 94 0.7244655581947743\n",
      "Troll Warlord 95 0.725925925925926\n",
      "Necrophos 36 0.7261306532663316\n",
      "Dazzle 50 0.7282608695652174\n",
      "Zeus 22 0.7358490566037735\n",
      "Lich 31 0.7373737373737373\n",
      "Dawnbreaker 135 0.7405660377358491\n",
      "Pangolier 120 0.7407407407407407\n",
      "Witch Doctor 30 0.74364896073903\n",
      "Dark Seer 55 0.7477477477477478\n",
      "Legion Commander 104 0.7515337423312883\n",
      "Tusk 100 0.7516778523489933\n",
      "Crystal Maiden 5 0.7545691906005222\n",
      "Bane 3 0.7690802348336595\n",
      "Brewmaster 78 0.7692307692307693\n",
      "Disruptor 87 0.7695652173913043\n",
      "Outworld Destroyer 76 0.7794117647058824\n",
      "Spirit Breaker 71 0.7815384615384615\n",
      "Oracle 111 0.7816901408450704\n",
      "Earthshaker 7 0.7818181818181819\n",
      "Naga Siren 89 0.782258064516129\n",
      "Drow Ranger 6 0.7831325301204819\n",
      "Magnus 97 0.7835648148148148\n",
      "Clockwerk 51 0.7839506172839507\n",
      "Bristleback 99 0.7865168539325843\n",
      "Slardar 28 0.7894736842105263\n",
      "Queen of Pain 39 0.7922437673130194\n",
      "Wraith King 42 0.7926078028747433\n",
      "Lina 25 0.7948717948717948\n",
      "Tidehunter 29 0.7962577962577962\n",
      "Sand King 16 0.7982456140350878\n",
      "Doom 69 0.8\n",
      "Earth Spirit 107 0.8076923076923077\n",
      "Arc Warden 113 0.8088235294117647\n",
      "Mars 129 0.8126272912423625\n",
      "Lycan 77 0.8289473684210527\n",
      "Night Stalker 60 0.8295819935691319\n",
      "Invoker 74 0.839541547277937\n",
      "Warlock 37 0.8410596026490066\n",
      "Lifestealer 54 0.8439024390243902\n",
      "Axe 2 0.8541666666666666\n",
      "Puck 13 0.863013698630137\n",
      "Beastmaster 38 0.8651685393258427\n",
      "Void Spirit 126 0.8696969696969697\n",
      "Underlord 108 0.8716216216216216\n",
      "Meepo 82 0.8723404255319149\n",
      "Ursa 70 0.8776470588235294\n",
      "Faceless Void 41 0.8798882681564246\n",
      "Tinker 34 0.8802395209580839\n",
      "Centaur Warrunner 96 0.8813559322033898\n",
      "Luna 48 0.8856015779092702\n",
      "Anti-Mage 1 0.8909574468085106\n",
      "Phantom Assassin 44 0.8909774436090225\n",
      "Sven 18 0.8963414634146342\n",
      "Ember Spirit 106 0.8994307400379506\n",
      "Templar Assassin 46 0.9\n",
      "Shadow Fiend 11 0.9001996007984032\n",
      "Slark 93 0.9092664092664092\n",
      "Juggernaut 8 0.9171171171171171\n",
      "Spectre 67 0.936734693877551\n",
      "Phantom Lancer 12 0.9590163934426229\n",
      "Terrorblade 109 0.9633507853403142\n",
      "Storm Spirit 17 0.9719626168224299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7314542161210236, 0.7261306532663316)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = list(scores_dict.items())\n",
    "a.sort(key=lambda x: x[1], reverse=False)\n",
    "\n",
    "hid_to_name = {x[\"id\"]:x[\"localized_name\"] for x in heroes}\n",
    "s_sum = []\n",
    "for k, v in a:\n",
    "    s_sum.append(v)\n",
    "    print(hid_to_name[k], k, v)\n",
    "\n",
    "np.mean(s_sum), np.median(s_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('gold_per_min', 16.82834187691858), ('xp_per_min', 4.534913684123263), ('kills', 4.553598039104362), ('deaths', 5.753761465307338), ('assists', 5.626764202281147), ('last_hits', 9.401213883965836), ('hero_damage', 5.269952380693461), ('tower_damage', 4.650736035260402)])\n"
     ]
    }
   ],
   "source": [
    "# sum_teammates = clfs[hid].feature_importances_[:136].sum()\n",
    "# sum_features = clfs[hid].feature_importances_[136:].sum()\n",
    "\n",
    "\n",
    "feature_sum = dict((k, 0.0) for k in [\"gold_per_min\", \"xp_per_min\", \"kills\", \"deaths\", \"assists\", \"last_hits\", \"hero_damage\", \"tower_damage\"])\n",
    "\n",
    "for hid in xs:\n",
    "    for k, l in enumerate([\"gold_per_min\", \"xp_per_min\", \"kills\", \"deaths\", \"assists\", \"last_hits\", \"hero_damage\", \"tower_damage\"]):\n",
    "        index = 136 + k * 5\n",
    "        s = clfs[hid].feature_importances_[index:index+5].sum()\n",
    "        feature_sum[l] += s\n",
    "\n",
    "\n",
    "\n",
    "pprint(feature_sum.items())\n",
    "# sum_teammates, sum_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'dict' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-1f0f6c0daaae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclfs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m136\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m136\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# clfs[31].feature_importances_[136:136+5]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/dota/lib/python3.8/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mrcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mrcount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'dict' and 'int'"
     ]
    }
   ],
   "source": [
    "print(np.array(scores).mean())\n",
    "\n",
    "clfs[1].coef_[0, 136:136+5]\n",
    "\n",
    "# clfs[31].feature_importances_[136:136+5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(scores).mean())\n",
    "\n",
    "clfs[31].coef_[4, 136:136+5]\n",
    "\n",
    "# clfs[31].feature_importances_[136:136+5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y, return_counts=True)\n",
    "print(unique, counts)\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(y)\n",
    "df.plot.hist(xticks=[1, 2, 3, 4, 5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score,cross_val_predict, train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "print(np.mean(y_pred == y_test))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "clf = LogisticRegression(random_state=0)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "print(np.mean(y_pred == y_test))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score,cross_val_predict, train_test_split\n",
    "\n",
    "\n",
    "# for hero, train a logistic regression model and add to VotingClassifier\n",
    "estimators = []\n",
    "\n",
    "\n",
    "clf = LogisticRegression(multi_class='multinomial', random_state=1)\n",
    "\n",
    "eclf1 = VotingClassifier(estimators=estimators, voting='hard')\n",
    "eclf1 = eclf1.fit(x_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "76d279d9dda3f104956abaa709c4930fec7a5837133fea297357827d52b43a61"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('dota': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
