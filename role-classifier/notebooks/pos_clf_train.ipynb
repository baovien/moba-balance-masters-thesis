{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pickle \n",
    "import tqdm\n",
    "import tarfile\n",
    "from scipy import sparse\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    with open(path, 'rb') as fp:\n",
    "        data = pickle.load(fp)\n",
    "\n",
    "    return data[\"xs\"], data[\"ys\"]\n",
    "\n",
    "def load_weights_dict(path):\n",
    "    with open(path, 'rb') as fp:\n",
    "        weights_dict = pickle.load(fp)\n",
    "    return weights_dict\n",
    "\n",
    "def get_dummy_classifier():\n",
    "    return DummyClassifier(strategy=\"constant\", constant=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 89/121 [00:45<00:13,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added classrole 1 for hero 65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:51<00:00,  2.36it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "\n",
    "output_path = \"../data/dataset_positions_winners.pkl\" \n",
    "weights_path = \"../data/weights_dict.pkl\"\n",
    "xs, ys = load_data(output_path)\n",
    "weights_dict = load_weights_dict(weights_path)\n",
    "\n",
    "clfs = {}\n",
    "scores = {}\n",
    "scores_dict = {}\n",
    "n_features = np.vstack(xs[1]).shape[1]\n",
    "for hid in tqdm.tqdm(xs):\n",
    "    try:\n",
    "        x = np.vstack(xs[hid])\n",
    "        y = np.hstack(ys[hid])\n",
    "        \n",
    "        class_weight = {e:v for e, v in enumerate(weights_dict[hid])}\n",
    "        unique = np.unique(np.hstack(ys[hid]))\n",
    "\n",
    "        for class_role in [1, 2, 3, 4, 5]:\n",
    "            if not class_role in unique.tolist():\n",
    "                print('added classrole', class_role, \"for hero\", hid)\n",
    "                xs[hid].append(np.zeros((n_features)))\n",
    "                ys[hid].append(class_role)\n",
    "\n",
    "        x = np.vstack(xs[hid])\n",
    "        y = np.hstack(ys[hid]) - 1\n",
    "\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        clf = LogisticRegression(multi_class=\"ovr\", max_iter=300, n_jobs=-1, solver=\"lbfgs\", class_weight=class_weight)\n",
    "        clf.fit(x_train, y_train)\n",
    "\n",
    "        score = clf.score(x_test, y_test)\n",
    "        clfs[hid] = clf\n",
    "        scores[hid] = score\n",
    "        scores_dict[hid] = score\n",
    "\n",
    "\n",
    "    except:\n",
    "        print(\"creashed on hid: \", hid)\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0]\n",
      " [   0    0    0    0    0]\n",
      " [  30  118 1969  227   34]\n",
      " [   0    0    1   50   24]\n",
      " [   0    0    0    0    1]]\n",
      "[0 1 2 3 4] [  30  118 1970  277   59]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "hid = 129\n",
    "print(confusion_matrix(clfs[hid].predict(np.vstack(xs[hid])), np.hstack(ys[hid])-1))\n",
    "\n",
    "counts, unique = np.unique(np.hstack(ys[hid])-1, return_counts=True)\n",
    "print(counts, unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[0 1 2 3 4] [1708  114 1632  365  417]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       1.00      0.83      0.91      2378\n",
      "           3       0.18      0.67      0.28        75\n",
      "           4       0.02      1.00      0.03         1\n",
      "\n",
      "    accuracy                           0.82      2454\n",
      "   macro avg       0.24      0.50      0.24      2454\n",
      "weighted avg       0.97      0.82      0.89      2454\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bao/anaconda3/envs/dota/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/bao/anaconda3/envs/dota/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/bao/anaconda3/envs/dota/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(clfs[hid].predict(np.vstack(xs[hid])), np.hstack(ys[hid])-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alchemist 73 0.43243243243243246\n",
      "Lone Druid 80 0.49056603773584906\n",
      "Keeper of the Light 90 0.5137614678899083\n",
      "Nature's Prophet 53 0.53125\n",
      "Omniknight 57 0.5333333333333333\n",
      "Vengeful Spirit 20 0.5529801324503312\n",
      "Techies 105 0.555956678700361\n",
      "Enchantress 58 0.5566037735849056\n",
      "Broodmother 61 0.56\n",
      "Bloodseeker 4 0.573170731707317\n",
      "Riki 32 0.5751295336787565\n",
      "Silencer 75 0.5798045602605864\n",
      "Undying 85 0.5844155844155844\n",
      "Rubick 86 0.5876460767946577\n",
      "Treant Protector 83 0.6060606060606061\n",
      "Bounty Hunter 62 0.6202090592334495\n",
      "Snapfire 128 0.6213592233009708\n",
      "Venomancer 40 0.624031007751938\n",
      "Chen 66 0.6296296296296297\n",
      "Nyx Assassin 88 0.6305732484076433\n",
      "Hoodwink 123 0.6318681318681318\n",
      "Pugna 45 0.6363636363636364\n",
      "Visage 92 0.6363636363636364\n",
      "Dark Willow 119 0.6385224274406333\n",
      "Skywrath Mage 101 0.638755980861244\n",
      "Razor 15 0.6412213740458015\n",
      "Clinkz 56 0.6413043478260869\n",
      "Viper 47 0.6416382252559727\n",
      "Shadow Demon 79 0.6481481481481481\n",
      "Dragon Knight 49 0.6483516483516484\n",
      "Pudge 14 0.6492462311557788\n",
      "Ogre Magi 84 0.6498740554156172\n",
      "Enigma 33 0.65\n",
      "Shadow Shaman 27 0.6591928251121076\n",
      "Elder Titan 103 0.6612903225806451\n",
      "Gyrocopter 72 0.6649214659685864\n",
      "Grimstroke 121 0.6655948553054662\n",
      "Monkey King 114 0.6661849710982659\n",
      "Huskar 59 0.6681614349775785\n",
      "Timbersaw 98 0.6687116564417178\n",
      "Phoenix 110 0.66875\n",
      "Winter Wyvern 112 0.6705539358600583\n",
      "Mirana 9 0.6745182012847966\n",
      "Lion 26 0.674712643678161\n",
      "Weaver 63 0.6788793103448276\n",
      "Io 91 0.6801346801346801\n",
      "Kunkka 23 0.6810126582278481\n",
      "Batrider 65 0.6823529411764706\n",
      "Sniper 35 0.6828046744574291\n",
      "Tiny 19 0.6847172081829122\n",
      "Jakiro 64 0.6848249027237354\n",
      "Leshrac 52 0.6850393700787402\n",
      "Abaddon 102 0.6857142857142857\n",
      "Death Prophet 43 0.6881720430107527\n",
      "Chaos Knight 81 0.7\n",
      "Morphling 10 0.7122641509433962\n",
      "Windranger 21 0.7165605095541401\n",
      "Ancient Apparition 68 0.7181008902077152\n",
      "Medusa 94 0.7244655581947743\n",
      "Troll Warlord 95 0.725925925925926\n",
      "Necrophos 36 0.7261306532663316\n",
      "Dazzle 50 0.7282608695652174\n",
      "Zeus 22 0.7358490566037735\n",
      "Lich 31 0.7373737373737373\n",
      "Dawnbreaker 135 0.7405660377358491\n",
      "Pangolier 120 0.7407407407407407\n",
      "Witch Doctor 30 0.74364896073903\n",
      "Dark Seer 55 0.7477477477477478\n",
      "Legion Commander 104 0.7515337423312883\n",
      "Tusk 100 0.7516778523489933\n",
      "Crystal Maiden 5 0.7545691906005222\n",
      "Bane 3 0.7690802348336595\n",
      "Brewmaster 78 0.7692307692307693\n",
      "Disruptor 87 0.7695652173913043\n",
      "Outworld Destroyer 76 0.7794117647058824\n",
      "Spirit Breaker 71 0.7815384615384615\n",
      "Oracle 111 0.7816901408450704\n",
      "Earthshaker 7 0.7818181818181819\n",
      "Naga Siren 89 0.782258064516129\n",
      "Drow Ranger 6 0.7831325301204819\n",
      "Magnus 97 0.7835648148148148\n",
      "Clockwerk 51 0.7839506172839507\n",
      "Bristleback 99 0.7865168539325843\n",
      "Slardar 28 0.7894736842105263\n",
      "Queen of Pain 39 0.7922437673130194\n",
      "Wraith King 42 0.7926078028747433\n",
      "Lina 25 0.7948717948717948\n",
      "Tidehunter 29 0.7962577962577962\n",
      "Sand King 16 0.7982456140350878\n",
      "Doom 69 0.8\n",
      "Earth Spirit 107 0.8076923076923077\n",
      "Arc Warden 113 0.8088235294117647\n",
      "Mars 129 0.8126272912423625\n",
      "Lycan 77 0.8289473684210527\n",
      "Night Stalker 60 0.8295819935691319\n",
      "Invoker 74 0.839541547277937\n",
      "Warlock 37 0.8410596026490066\n",
      "Lifestealer 54 0.8439024390243902\n",
      "Axe 2 0.8541666666666666\n",
      "Puck 13 0.863013698630137\n",
      "Beastmaster 38 0.8651685393258427\n",
      "Void Spirit 126 0.8696969696969697\n",
      "Underlord 108 0.8716216216216216\n",
      "Meepo 82 0.8723404255319149\n",
      "Ursa 70 0.8776470588235294\n",
      "Faceless Void 41 0.8798882681564246\n",
      "Tinker 34 0.8802395209580839\n",
      "Centaur Warrunner 96 0.8813559322033898\n",
      "Luna 48 0.8856015779092702\n",
      "Anti-Mage 1 0.8909574468085106\n",
      "Phantom Assassin 44 0.8909774436090225\n",
      "Sven 18 0.8963414634146342\n",
      "Ember Spirit 106 0.8994307400379506\n",
      "Templar Assassin 46 0.9\n",
      "Shadow Fiend 11 0.9001996007984032\n",
      "Slark 93 0.9092664092664092\n",
      "Juggernaut 8 0.9171171171171171\n",
      "Spectre 67 0.936734693877551\n",
      "Phantom Lancer 12 0.9590163934426229\n",
      "Terrorblade 109 0.9633507853403142\n",
      "Storm Spirit 17 0.9719626168224299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7314542161210236, 0.7261306532663316)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = list(scores_dict.items())\n",
    "a.sort(key=lambda x: x[1], reverse=False)\n",
    "\n",
    "hid_to_name = {x[\"id\"]:x[\"localized_name\"] for x in heroes}\n",
    "s_sum = []\n",
    "for k, v in a:\n",
    "    s_sum.append(v)\n",
    "    print(hid_to_name[k], k, v)\n",
    "\n",
    "np.mean(s_sum), np.median(s_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y, return_counts=True)\n",
    "print(unique, counts)\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(y)\n",
    "df.plot.hist(xticks=[1, 2, 3, 4, 5])\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "76d279d9dda3f104956abaa709c4930fec7a5837133fea297357827d52b43a61"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('dota': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
