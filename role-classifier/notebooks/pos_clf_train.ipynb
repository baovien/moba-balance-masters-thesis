{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pickle \n",
    "import tqdm\n",
    "import tarfile\n",
    "from scipy import sparse\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"../data/dataset_positions.pkl\" \n",
    "\n",
    "with open(output_path, 'rb') as fp:\n",
    "    data = pickle.load(fp)\n",
    "\n",
    "xs = data[\"xs\"]\n",
    "ys = data[\"ys\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 27\n",
      "28 28\n",
      "31 31\n",
      "27 27\n",
      "28 28\n"
     ]
    }
   ],
   "source": [
    "with open(\"../../data/heroes.json\", \"r\") as fp:\n",
    "  heroes = json.load(fp)\n",
    "\n",
    "safelane = [\"Anti-Mage\", \"Arc Warden\", \"Bloodseeker\", \"Chaos Knight\", \"Clinkz\", \"Drow Ranger\", \"Faceless Void\", \n",
    "\"Gyrocopter\", \"Juggernaut\", \"Lifestealer\", \"Luna\", \"Medusa\", \"Monkey King\", \"Morphling\", \"Naga Siren\", \"Phantom Assassin\", \n",
    "\"Phantom Lancer\", \"Riki\", \"Slark\", \"Spectre\", \"Sven\", \"Terrorblade\", \"Tiny\", \"Troll Warlord\", \"Ursa\", \"Weaver\", \"Wraith King\"]\n",
    "safelane_name_to_id = [x[\"id\"] for x in heroes if x[\"localized_name\"] in safelane]\n",
    "print(len(safelane), len(safelane_name_to_id))\n",
    "\n",
    "midlane = [\"Alchemist\", \"Arc Warden\", \"Batrider\", \"Broodmother\", \"Death Prophet\", \"Ember Spirit\", \n",
    "\"Huskar\", \"Invoker\", \"Kunkka\", \"Leshrac\", \"Lina\", \"Lone Druid\", \"Meepo\", \"Necrophos\", \"Outworld Destroyer\", \n",
    "\"Puck\", \"Pugna\", \"Queen of Pain\", \"Razor\", \"Shadow Fiend\", \"Sniper\", \"Storm Spirit\", \n",
    "\"Templar Assassin\", \"Tinker\", \"Viper\", \"Visage\", \"Void Spirit\", \"Zeus\"]\n",
    "midlane_name_to_id = [x[\"id\"] for x in heroes if x[\"localized_name\"] in midlane]\n",
    "print(len(midlane), len(midlane_name_to_id))\n",
    "\n",
    "offlane = [\"Axe\", \"Beastmaster\", \"Bloodseeker\", \"Brewmaster\", \"Bristleback\", \n",
    "\"Centaur Warrunner\", \"Chaos Knight\", \"Dark Seer\", \"Dawnbreaker\", \"Death Prophet\", \"Doom\", \n",
    "\"Dragon Knight\", \"Earthshaker\", \"Elder Titan\", \"Enigma\", \"Legion Commander\", \"Lycan\", \n",
    "\"Mars\", \"Nature's Prophet\", \"Necrophos\", \"Night Stalker\", \"Pangolier\", \n",
    "\"Razor\", \"Sand King\", \"Slardar\", \"Spirit Breaker\", \"Tidehunter\", \"Timbersaw\", \"Underlord\", \"Venomancer\", \"Viper\"]\n",
    "\n",
    "offlane_name_to_id = [x[\"id\"] for x in heroes if x[\"localized_name\"] in offlane]\n",
    "print(len(offlane),len(offlane_name_to_id))\n",
    "\n",
    "soft_support = [\"Bounty Hunter\", \"Chen\", \"Clockwerk\", \"Dark Willow\", \"Earth Spirit\", \"Earthshaker\", \"Enigma\", \n",
    "\"Grimstroke\", \"Hoodwink\", \"Keeper of the Light\", \"Mirana\", \"Nyx Assassin\", \"Phoenix\", \"Pudge\", \"Rubick\", \n",
    "\"Shadow Demon\", \"Shadow Shaman\", \"Silencer\", \"Skywrath Mage\", \"Snapfire\", \"Spirit Breaker\", \"Techies\", \n",
    "\"Treant Protector\", \"Tusk\", \"Venomancer\", \"Weaver\", \"Windranger\"]\n",
    "\n",
    "soft_support_name_to_id = [x[\"id\"] for x in heroes if x[\"localized_name\"] in soft_support]\n",
    "print(len(soft_support), len(soft_support_name_to_id))\n",
    "\n",
    "hard_support = [\"Abaddon\", \"Ancient Apparition\", \"Bane\", \"Chen\", \"Crystal Maiden\", \"Dark Willow\", \"Dazzle\", \"Disruptor\", \n",
    "\"Enchantress\", \"Grimstroke\", \"Io\", \"Jakiro\", \"Keeper of the Light\", \"Lich\", \"Lion\", \"Ogre Magi\", \"Omniknight\", \"Oracle\", \"Shadow Demon\", \n",
    "\"Shadow Shaman\", \"Silencer\", \"Snapfire\", \"Treant Protector\", \"Vengeful Spirit\", \"Undying\", \"Warlock\", \"Winter Wyvern\", \"Witch Doctor\"]\n",
    "hard_support_name_to_id = [x[\"id\"] for x in heroes if x[\"localized_name\"] in hard_support]\n",
    "print(len(hard_support), len(hard_support_name_to_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_dict = defaultdict(lambda: np.zeros(5))\n",
    "\n",
    "for h in heroes:\n",
    "    weights_dict[h[\"id\"]] = np.array([.1, .1, .1, .1, .1])\n",
    "\n",
    "lane_assist = [safelane_name_to_id, midlane_name_to_id, offlane_name_to_id, soft_support_name_to_id, hard_support_name_to_id]\n",
    "\n",
    "for k, lane in enumerate(lane_assist):\n",
    "    for hid in lane:\n",
    "        weights_dict[hid][k] = 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.0, 1: 0.1, 2: 1.0, 3: 0.1, 4: 0.1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{e:v for e, v in enumerate(weights_dict[4])}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [01:39<00:00,  1.22it/s]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "clfs = []\n",
    "scores = []\n",
    "scores_dict = {}\n",
    "\n",
    "for hid in tqdm.tqdm(xs):\n",
    "    x = np.vstack(xs[hid])\n",
    "    y = np.hstack(ys[hid]) - 1\n",
    "    \n",
    "    class_weight = {e:v for e, v in enumerate(weights_dict[hid])}\n",
    "    clf = LogisticRegression(multi_class=\"ovr\", max_iter=300, n_jobs=-1, solver=\"lbfgs\", class_weight=class_weight)\n",
    "    # clf = RandomForestClassifier()\n",
    "    clf.fit(x, y)\n",
    "\n",
    "    score = clf.score(x,y)\n",
    "    clfs.append(clf)\n",
    "    scores.append(score)\n",
    "    scores_dict[hid] = score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5073834651239812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.67401485,  0.64140675,  0.5257871 , -0.0839084 , -1.75650057])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.array(scores).mean())\n",
    "\n",
    "clfs[1].coef_[0, 136:136+5]\n",
    "\n",
    "# clfs[31].feature_importances_[136:136+5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(scores).mean())\n",
    "\n",
    "clfs[31].coef_[4, 136:136+5]\n",
    "\n",
    "# clfs[31].feature_importances_[136:136+5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y, return_counts=True)\n",
    "print(unique, counts)\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(y)\n",
    "df.plot.hist(xticks=[1, 2, 3, 4, 5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.model_selection import cross_val_score,cross_val_predict, train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "print(np.mean(y_pred == y_test))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "clf = LogisticRegression(random_state=0)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "print(np.mean(y_pred == y_test))\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score,cross_val_predict, train_test_split\n",
    "\n",
    "\n",
    "# for hero, train a logistic regression model and add to VotingClassifier\n",
    "estimators = []\n",
    "\n",
    "\n",
    "clf = LogisticRegression(multi_class='multinomial', random_state=1)\n",
    "\n",
    "eclf1 = VotingClassifier(estimators=estimators, voting='hard')\n",
    "eclf1 = eclf1.fit(x_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "76d279d9dda3f104956abaa709c4930fec7a5837133fea297357827d52b43a61"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('dota': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
